pub_date	title	venue	excerpt	citation	url_slug	paper_url	short_proceeding
2017-01-14	"Partitioning dynamic graph asynchronously with distributed FENNEL"	"Future Generation Computer Systems, Volume 71, 2017, Pages 32-42, ISSN 0167-739X"	"Graph partitioning is important in distributed graph processing. Classical method such as METIS works well on relatively small graphs, but hard to scale for huge, dynamic graphs. Streaming graph partitioning algorithms overcome this issue by processing those graphs as streams. Among these algorithms, FENNEL achieves better edge cut ratio, even close to METIS, but consumes less memory and is significantly faster. On the other hand, graph partitioning may also benefit from distributed graph processing. However, to deploy FENNEL on a cluster, it is important to avoid quality loss and keep efficiency high. The direct implementation of this idea yields a synchronous model and a star-shaped network, which limits both scalability and efficiency. Targeting these two problems, we propose an asynchronous model, combined with a dedicated tree-shaped map-reduce network which is prevail in systems such as Apache Hadoop and Spark, to form AsyncFENNEL (asynchronous FENNEL). We theoretically prove that, the impact on partition quality brought by asynchronous model can be kept as minimal. We test AsyncFENNEL with various synthetic and real-world graphs, the comparison between synchronous and asynchronous models shows that, for streamed natural graphs, AsyncFENNEL can improve performance significantly (above 300% with 8 workers/partitions) with negligible loss on edge cut ratio. However, more worker nodes will introduce a heavier network traffic and reduce efficiency. The proposed tree-shaped map-reduce network can mitigate that impact and increase the performance in that case."	"Zhan Shi, Junhao Li, Pengfei Guo, Shuangshuang Li, Dan Feng, Yi Su, Partitioning dynamic graph asynchronously with distributed FENNEL, Future Generation Computer Systems, Volume 71, 2017, Pages 32-42, ISSN 0167-739X, http://dx.doi.org/10.1016/j.future.2017.01.014."	"FGCS-graphpartition-201701"	"../files/FGCS-graphpartition-201701.pdf"	"FGCS"
2017-08-14	"Predicting Response Latency Percentiles for Cloud Object Storage Systems"	"Proceedings of the 46th International Conference on Parallel Processing (ICPP)"	"As a fundamental cloud service for modern Web applications, the cloud object storage system stores and retrieves millions or even billions of read-heavy data objects. Serving for a massive amount of requests each day makes the response latency be a vital component of user experiences. Due to the lack of suitable understanding on the response latency distribution, current practice is to use overprovision resources to meet Service Level Agreement (SLA). Hence we build a performance model for the cloud object storage system to predict the percentiles of requests meeting SLA (response latency requirement), in the context of complicated disk operations and event-driven programming model. Furthermore, we find that the waiting time for being accept()-ed at storage servers may introduce significant delay. And we quantify the impacts on system response latency, due to requests waiting for being accept()-ed. In a variety of scenarios, our model reduces the prediction errors by up to 73% compared to baseline models, and the prediction error of our model is 4.44% on average."	"Yi Su, Dan Feng, Yu Hua, Zhan Shi, Predicting Response Latency Percentiles for Cloud Object Storage Systems, in the 46th International Conference on Parallel Processing (ICPP), 2017, pp. 241-250."	"ICPP-cosmodel-201708"	"../files/ICPP-cosmodel-201708.pdf"	"ICPP"
2018-07-02	"NetRS: Cutting Response Latency in Distributed Key-Value Stores with In-Network Replica Selection"	"Proceedings of the 38th IEEE International Conference on Distributed Computing Systems (ICDCS)"	"In distributed key-value stores, performance fluctuations generally occur across servers, especially when the servers are deployed in a cloud environment. Hence, the replica selected for a request will directly affect the response latency. In the context of key-value stores, even the state-of-the-art algorithm of replica selection still has considerable room for improving the response latency. In this paper, we present the fundamental factors that prevent replica selection algorithms from being effective. We address these factors by proposing NetRS, a framework that enables in-network replica selection for key-value stores. NetRS exploits emerging network devices, including programmable switches and network accelerators, to select replicas for requests. NetRS supports diverse algorithms of replica selection and is suited to the network topology of modern data centers. Compared with the conventional scheme of clients selecting replicas for requests, NetRS could effectively cut the response latency according to our extensive evaluations. Specifically, NetRS reduces the average latency by up to 48.4%, and the 99th latency by up to 68.7%."	"Yi Su, Dan Feng, Yu Hua, Zhan Shi, Tingwei Zhu, NetRS: Cutting Response Latency in Distributed Key-Value Stores with In-Network Replica Selection, in the 38th IEEE International Conference on Distributed Computing Systems (ICDCS), 2018, pp. 143-153."	"ICDCS-NetRS-201807"	"../files/ICDCS-NetRS-201807.pdf"	"ICDCS"
2019-02-28	"Understanding the latency distribution of cloud object storage systems"	"Journal of Parallel and Distributed Computing, Volume 128, 2019, Pages 71-83, ISSN 0743-7315"	"As a fundamental cloud service, the cloud object storage system stores and retrieves millions or even billions of read-heavy data objects. Serving for a massive amount of requests each day makes the response latency be a vital component of user experiences. Timeout is also a key issue as it has a great impact on the response latency. Due to the lack of suitable understanding on the distribution of the response latency and the occurrence of timeouts, current practice is to use overprovision resources to meet a Service Level Agreement (SLA) on response latency. Hence, firstly, we build a performance model for the cloud object storage system, which assumes no timeout occurring. Our model predicts the percentage of requests meeting an SLA, in the context of complicated disk operations, event-driven programming model and requests waiting for being accept()-ed. Secondly, we propose a method that determines whether or not our model is applicable by predicting the occurrence of timeouts. We evaluate our model with a production system using a real-world trace. In a variety of scenarios, our model reduces the prediction errors by up to 90% compared with baseline models, and its overall average error is 2.63%. Moreover, we could also accurately predict the applicability of our model."	"Yi Su, Dan Feng, Yu Hua, Zhan Shi, Understanding the latency distribution of cloud object storage systems, Journal of Parallel and Distributed Computing, Volume 128, 2019, Pages 71-83, ISSN 0743-7315, https://doi.org/10.1016/j.jpdc.2019.01.008."	"JPDC-cosmodel-201902"	"../files/JPDC-cosmodel-201902.pdf"	"JPDC"
