pub_date	title	venue	excerpt	citation	url_slug	paper_url
2017-01-14	"Partitioning dynamic graph asynchronously with distributed FENNEL"	"Future Generation Computer Systems, Volume 71, 2017, Pages 32-42, ISSN 0167-739X"	"Graph partitioning is important in distributed graph processing. Classical method such as METIS works well on relatively small graphs, but hard to scale for huge, dynamic graphs. Streaming graph partitioning algorithms overcome this issue by processing those graphs as streams. Among these algorithms, FENNEL achieves better edge cut ratio, even close to METIS, but consumes less memory and is significantly faster. On the other hand, graph partitioning may also benefit from distributed graph processing. However, to deploy FENNEL on a cluster, it is important to avoid quality loss and keep efficiency high. The direct implementation of this idea yields a synchronous model and a star-shaped network, which limits both scalability and efficiency. Targeting these two problems, we propose an asynchronous model, combined with a dedicated tree-shaped map-reduce network which is prevail in systems such as Apache Hadoop and Spark, to form AsyncFENNEL (asynchronous FENNEL). We theoretically prove that, the impact on partition quality brought by asynchronous model can be kept as minimal. We test AsyncFENNEL with various synthetic and real-world graphs, the comparison between synchronous and asynchronous models shows that, for streamed natural graphs, AsyncFENNEL can improve performance significantly (above 300% with 8 workers/partitions) with negligible loss on edge cut ratio. However, more worker nodes will introduce a heavier network traffic and reduce efficiency. The proposed tree-shaped map-reduce network can mitigate that impact and increase the performance in that case."	"Zhan Shi, Junhao Li, Pengfei Guo, Shuangshuang Li, Dan Feng, Yi Su, Partitioning dynamic graph asynchronously with distributed FENNEL, Future Generation Computer Systems, Volume 71, 2017, Pages 32-42, ISSN 0167-739X, http://dx.doi.org/10.1016/j.future.2017.01.014."	"FGCS-graphpartition-201701"	"../files/FGCS-graphpartition-201701.pdf"
2017-08-14	"Predicting Response Latency Percentiles for Cloud Object Storage Systems"	"Proceedings of the 46th International Conference on Parallel Processing (ICPP)"	"As a fundamental cloud service for modern Web applications, the cloud object storage system stores and retrieves millions or even billions of read-heavy data objects. Serving for a massive amount of requests each day makes the response latency be a vital component of user experiences. Due to the lack of suitable understanding on the response latency distribution, current practice is to use overprovision resources to meet Service Level Agreement (SLA). Hence we build a performance model for the cloud object storage system to predict the percentiles of requests meeting SLA (response latency requirement), in the context of complicated disk operations and event-driven programming model. Furthermore, we find that the waiting time for being accept()-ed at storage servers may introduce significant delay. And we quantify the impacts on system response latency, due to requests waiting for being accept()-ed. In a variety of scenarios, our model reduces the prediction errors by up to 73% compared to baseline models, and the prediction error of our model is 4.44% on average."	"Yi Su, Dan Feng, Yu Hua, Zhan Shi, Predicting Response Latency Percentiles for Cloud Object Storage Systems, in 2017 46th International Conference on Parallel Processing (ICPP), 2017, pp. 241-250."	"ICPP-cosmodel-201708"	"../files/ICPP-cosmodel-201708.pdf"
